{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODUdZhOjd0QVnCCxmABS5C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Xo3LUfNnvMht"},"outputs":[],"source":["!pip install transformers\n","!pip install auto_gptq"]},{"cell_type":"markdown","source":["takes in pdf file as input and it will count the number of tokens in a pdf file"],"metadata":{"id":"lNsT_smTwSdA"}},{"cell_type":"code","source":["from transformers import GPT2Tokenizer\n","import PyPDF2\n","\n","def count_tokens_in_pdf(pdf_path):\n","    total_tokens = 0\n","    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","    with open(pdf_path, 'rb') as file:\n","        pdf_reader = PyPDF2.PdfReader('/content/1daytoken.pdf')\n","\n","        for page_number in range(len(pdf_reader.pages)):\n","            page = pdf_reader.pages[page_number]\n","            text = page.extract_text()\n","            tokens = tokenizer(text)['input_ids']\n","            total_tokens += len(tokens)\n","\n","    return total_tokens\n","print(count_tokens_in_pdf('/content/1daytoken.pdf'))"],"metadata":{"id":"--0pGZ0Uv--u"},"execution_count":null,"outputs":[]}]}